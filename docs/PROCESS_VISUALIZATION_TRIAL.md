# \# Process Visualization â€” rag-ollama-set-up (end-to-end)

This page visualizes the full workflow we implemented:
- PostgreSQL + pgvector (vector DB + HNSW index)
- Ollama embeddings (bge-m3) + Ollama chat (gemma3:4b)
- Python scripts for ingestion, retrieval, generation, logging, and testing

---

```mermaid
flowchart TD

  subgraph Setup["Setup<br/>"]
    S1["Install + Configure"] --> S2["DB ready + Models ready"]
  end  

  S2 --> R0["â–¶ Start Runtime"]
  subgraph Runtime["Runtime"]
    R0 --> Ingest["ğŸ“¥ Ingest docs (ingest.py)"]
    Ingest --> Chunk["âœ‚ï¸ Chunk text"]
    Chunk --> EmbedDocs["ğŸ§  Embed docs (bge-m3)"]
    EmbedDocs --> Store["ğŸ—„ï¸ Store in rag_chunks"]
  end

```
---

```mermaid
flowchart TD

  START([ğŸš€Start]) --> AUTH{Authentication enabled?}

  AUTH -- "No" --> DENY[âŒ Access denied] --> END0([End])

  AUTH -- "Yes" --> ROLE[ğŸ‘¥ Load user role + groups]
  ROLE --> PERM[ğŸ” Permission check: what data can this user access?]

  PERM --> HASRAG{RAG available for this question/user?}

  HASRAG -- "No" --> LLMONLY["ğŸ’¬ Ask LLM directly<br/>(no RAG)"]
  LLMONLY --> LOG0[("ğŸ“ Log to qa_log)"]
  LOG0 --> END([âœ… Done])

  HASRAG -- "Yes" --> ROUTE["ğŸ§­ Route to respective RAG<br/>(client / internal / external)"]

  %% --- RAG Retrieval + Relevancy Gate ---
  ROUTE --> Q["ğŸ§  Embed question (bge-m3)"]
  Q --> S[ğŸ” Search the database for most similar saved parts]
  S --> R[ğŸ“¦ Pick the 5 most relevant text snippets and how strongly they match the question]

  R --> G{ğŸ¯ Relevant enough?}

  %% Not relevant path
  G -- "No ğŸ˜•" --> N[ğŸ™… Reply: Not enough info<br/>Ask user for more context]
  N --> L1[(ğŸ“ Log to qa_log)]
  classDef animate stroke-dasharray: 9,5,stroke-dashoffset: 900,animation: dash 25s linear infinite;
  class e1 animate

  %% Relevant path
  G -- "Yes âœ…" --> C[ğŸ§© Build context prompt<br/>chunks + citations]
  C --> A[ğŸ’¬ Answer with Ollama<br/>gemma3:4b]
  A --> L2[(ğŸ“ Log to qa_log)]

  %% --- Optional audit ---
  L2 --> AU{ğŸ•µï¸ Audit enabled?}
  AU -- "No" --> DONE([âœ… Done])

  AU -- "Yes" --> J[ğŸ§ª LLM Judge: quality + groundedness]
  J --> V{âœ… Pass?}

  V -- "Yes" --> DONE
  V -- "No" --> F[(ğŸ—³ï¸ Store feedback / failure)]
  F --> DONE

```

---

```mermaid

flowchart LR

  D["ğŸ“ Best similarity score"] --> T{"score â‰¤ MAX_DISTANCE?"}
  H["ğŸ”¢ Relevant chunks found"] --> M{"hits â‰¥ MIN_HITS?"}
  C["ğŸ§¾ Context length"] --> K{"chars â‰¥ MIN_CONTEXT_CHARS?"}

  T --> AND{"All checks pass?"}
  M --> AND
  K --> AND

  AND -- "Yes âœ…" --> G["âœ… Relevant â†’ Use RAG context"]
  AND -- "No âŒ" --> N["âŒ Not relevant â†’ No-RAG / ask for more info"]


```
